workflow:
  name: "Random+Comprehensive Sampling Workflow"
  actions:
    - id: read_file
      action: READ_FILE_CSV
      parameters:
        urlpath: "/driver_test_scores/input_data/csv_data.csv"

    - id: random_fraction_sample
      action: SAMPLE_RANDOM
      parameters:
        frac: 0.2 # 20%
        random_state: 13
      dependencies: ["read_file"]
    
    - id: comprehensive_sample
      action: SAMPLE_COMPREHENSIVE
      parameters:
        miner_config:
          ignore_fields_regex: ["id"]
        type_config:
          age: int64
          score: float32
      dependencies: ["read_file"]

    - id: merge_samples
      action: MERGE
      dependencies: ["random_fraction_sample", "comprehensive_sample"]

    - id: deduplicate_samples
      action: DEDUPLICATE
      dependencies: ["merge_samples"]

    - id: write_file
      action: WRITE_FILE_CSV
      parameters:
        filename: "/driver_test_scores/output_data/csv_output.csv"
        single_file: true
      dependencies: ["deduplicate_samples"]

workflow_runner:
  cluster_class: "dask.distributed.LocalCluster"
  cluster_kwargs:
    n_workers: 1
    threads_per_worker: 1
    processes: true
    preload: "from bytesizer.utils.logging import setup_logger; setup_logger()"
