workflow:
  name: "Random + Comprehensive Sampling Workflow"
  actions:
    - id: read_file
      action: READ_FILE_JSON
      parameters:
        url_path: "/driver_test_scores/input_data/json_data.json"

    - id: random_sample
      action: SAMPLE_RANDOM
      parameters:
        frac: 0.2 # 20%
        random_state: 13
      dependencies: ["read_file"]

    - id: comprehensive_sample
      action: SAMPLE_COMPREHENSIVE
      parameters:
        rounds: 2
        miner_config:
          ignore_fields_regex: ["id"]
        type_config:
          age: int64
          score: float32
      dependencies: ["read_file"]

    - id: merge_samples
      action: MERGE
      dependencies: ["random_sample", "comprehensive_sample"]

    - id: deduplicate
      action: DEDUPLICATE
      dependencies: ["merge_samples"]

    - id: write_file
      action: WRITE_FILE_JSON
      parameters:
        path_or_buf: "/driver_test_scores/output_data/json_output.json"
        single_file: true
        orient: records
        lines: true
      dependencies: ["deduplicate"]

workflow_runner:
  cluster_class: "dask.distributed.LocalCluster"
  cluster_kwargs:
    n_workers: 1
    threads_per_worker: 1
